<!DOCTYPE html><html lang="zh-CN"><head><meta charset="utf-8"><meta name="X-UA-Compatible" content="IE=edge"><meta name="author" content="阳光夜风"><title>阳光夜风</title><meta name="description" content="A Blog Powered By Hexo"><meta name="keywords" content="iOS, Apple Foundation, Machine Learning, Algorithm, LeetCode"><meta content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=0" name="viewport"><meta content="yes" name="apple-mobile-web-app-capable"><meta content="black" name="apple-mobile-web-app-status-bar-style"><meta content="telephone=no" name="format-detection"><meta name="renderer" content="webkit"><link rel="short icon" href="/images/favicon.png" type="image/x-icon"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/blog_basic.css"><link rel="stylesheet" href="/css/font-awesome.min.css"><link rel="alternate" type="application/atom+xml" title="ATOM 1.0" href="/atom.xml"></head><body><div class="sidebar animated fadeInDown"><div class="logo-title"><div class="title"><img src="/images/logo@2x.png" style="width:127px;"><h3 title=""><a href="/">阳光夜风</a></h3><div class="description"><p>上善若水 大盈若冲</p></div></div></div><ul class="social-links"><li><a href="http://weibo.com/1685261185"><i class="fa fa-weibo"></i></a></li></ul><div class="footer"></div></div><div class="main"><div class="page-top animated fadeInDown"><div class="nav"><li><a class="current" href="/">首页</a></li><li><a href="/categories/">分类</a></li><li><a href="/tags">标签</a></li><li><a href="/archives">归档</a></li></div><div class="information"><div class="back_btn"><li><a class="fa fa-chevron-left" onclick="window.history.go(-1)" style="display:none;"></a></li></div><div class="avatar"><img src="/images/favicon.png"></div></div></div><div class="autopagerize_page_element"><div class="content"><div class="post animated fadeInDown"><div class="post-title"><h3><a href="/posts/【课程笔记】精准率与召回率/">【课程笔记】精准率与召回率及F1分数</a></h3></div><div class="post-content"><p>精准率跟召回率的定义跟原理就不赘述了，这里主要还是加深一下对这两个值的理解。还是先上公式：$精准率：$

precision = \frac{True Positive}{True Positive + False Positive}$召回率：$

recall = \frac{True Positive}{Tr...</p></div><div class="post-footer"><div class="meta"><div class="info"><i class="fa fa-sun-o"></i><span class="date">2017-07-22</span><i class="fa fa-comment-o"></i><a href="/posts/【课程笔记】精准率与召回率/#comments">评论</a><i class="fa fa-tag"></i><a class="tag" href="/categories/机器学习/" title="机器学习">机器学习 </a><a class="tag" href="/tags/机器学习/" title="机器学习">机器学习 </a><a class="tag" href="/tags/ml/" title="ml">ml </a><a class="tag" href="/tags/machine-learning/" title="machine learning">machine learning </a></div></div></div></div><div class="post animated fadeInDown"><div class="post-title"><h3><a href="/posts/【课程笔记】异常值/">【课程笔记】异常值</a></h3></div><div class="post-content"><p>残差对训练集拟合之后，训练集本身对该拟合的误差。（注意：即使是训练集也是有误差的，不然完全一样的话就过拟合了）
去除方法拟合之后，去掉残差最大的一部分（通常10%），然后重新拟合，反复多次。
</p></div><div class="post-footer"><div class="meta"><div class="info"><i class="fa fa-sun-o"></i><span class="date">2017-07-20</span><i class="fa fa-comment-o"></i><a href="/posts/【课程笔记】异常值/#comments">评论</a><i class="fa fa-tag"></i><a class="tag" href="/categories/机器学习/" title="机器学习">机器学习 </a><a class="tag" href="/tags/机器学习/" title="机器学习">机器学习 </a><a class="tag" href="/tags/ml/" title="ml">ml </a><a class="tag" href="/tags/machine-learning/" title="machine learning">machine learning </a></div></div></div></div><div class="post animated fadeInDown"><div class="post-title"><h3><a href="/posts/【课程笔记】分类跟回归的比较/">【课程笔记】分类跟回归的比较</a></h3></div><div class="post-content"><p>





分类
回归




输出类型
离散
连续


本质
寻找决策边界（decision boundary）
寻找最佳拟合线


如何评价
准确率（accuracy）
误差平方和（SSE）或 R2




</p></div><div class="post-footer"><div class="meta"><div class="info"><i class="fa fa-sun-o"></i><span class="date">2017-07-20</span><i class="fa fa-comment-o"></i><a href="/posts/【课程笔记】分类跟回归的比较/#comments">评论</a><i class="fa fa-tag"></i><a class="tag" href="/categories/机器学习/" title="机器学习">机器学习 </a><a class="tag" href="/tags/机器学习/" title="机器学习">机器学习 </a><a class="tag" href="/tags/ml/" title="ml">ml </a><a class="tag" href="/tags/machine-learning/" title="machine learning">machine learning </a></div></div></div></div><div class="post animated fadeInDown"><div class="post-title"><h3><a href="/posts/【课程笔记】分类/">【课程笔记】分类</a></h3></div><div class="post-content"><p>分类：离散数据回归：连续数据
本质：找到决策边界（decision boundary）
</p></div><div class="post-footer"><div class="meta"><div class="info"><i class="fa fa-sun-o"></i><span class="date">2017-07-20</span><i class="fa fa-comment-o"></i><a href="/posts/【课程笔记】分类/#comments">评论</a><i class="fa fa-tag"></i><a class="tag" href="/categories/机器学习/" title="机器学习">机器学习 </a><a class="tag" href="/tags/机器学习/" title="机器学习">机器学习 </a><a class="tag" href="/tags/ml/" title="ml">ml </a><a class="tag" href="/tags/machine-learning/" title="machine learning">machine learning </a></div></div></div></div><div class="post animated fadeInDown"><div class="post-title"><h3><a href="/posts/【课程笔记】回归/">【课程笔记】回归</a></h3></div><div class="post-content"><p>回归：连续数据分类：离散数据
本质：找到最佳拟合线
线性回归本质：找到y跟x之间的线性关系

y = mx + b

m是斜率（slope），b是截距（intercept）在sklearn中，斜率保存在 reg.coef_ 参数中，截距保存在 reg.intercept_ 参数中。

线性回归误差
误差平方和（S...</p></div><div class="post-footer"><div class="meta"><div class="info"><i class="fa fa-sun-o"></i><span class="date">2017-07-20</span><i class="fa fa-comment-o"></i><a href="/posts/【课程笔记】回归/#comments">评论</a><i class="fa fa-tag"></i><a class="tag" href="/categories/机器学习/" title="机器学习">机器学习 </a><a class="tag" href="/tags/机器学习/" title="机器学习">机器学习 </a><a class="tag" href="/tags/ml/" title="ml">ml </a><a class="tag" href="/tags/machine-learning/" title="machine learning">machine learning </a></div></div></div></div><div class="post animated fadeInDown"><div class="post-title"><h3><a href="/posts/np-std跟pd-std的区别/">np.std跟pd.std的区别</a></h3></div><div class="post-content"><p>首先上文档
numpy:
然后是pandas:

所以此处区别就明显了，np中求平均的时候除以的是数据的总数N，而pd中却是N-1。
为什么要除以N-1呢？这就涉及到一个名词：wiki: 贝塞尔校正这个问题在numpy文档的下面紧接着也解释了，照例，还是先上文档：

关键句在这里：In standard stat...</p></div><div class="post-footer"><div class="meta"><div class="info"><i class="fa fa-sun-o"></i><span class="date">2017-07-20</span><i class="fa fa-comment-o"></i><a href="/posts/np-std跟pd-std的区别/#comments">评论</a><i class="fa fa-tag"></i><a class="tag" href="/tags/机器学习/" title="机器学习">机器学习 </a></div></div></div></div><div class="post animated fadeInDown"><div class="post-title"><h3><a href="/posts/sklearn中OneHotEncoder/">sklearn中OneHotEncoder</a></h3></div><div class="post-content"><p>OneHotEncoder输入必须是int数组，所以直接传入字符串特征值是不行的，需要先通过LabelEncoder转化成整型特征，再传入OneHotEncoder。
12345le = LabelEncoder()df.feature = le.fit_transform(df.feature)ohe = On...</p></div><div class="post-footer"><div class="meta"><div class="info"><i class="fa fa-sun-o"></i><span class="date">2017-07-20</span><i class="fa fa-comment-o"></i><a href="/posts/sklearn中OneHotEncoder/#comments">评论</a><i class="fa fa-tag"></i><a class="tag" href="/tags/机器学习/" title="机器学习">机器学习 </a></div></div></div></div><div class="post animated fadeInDown"><div class="post-title"><h3><a href="/posts/numpy中mean跟average区别/">numpy中mean跟average区别</a></h3></div><div class="post-content"><p>np.mean直接计算平均数np.average计算加权平均数（如果有权重weight的话）
部分源码
np.mean:12345try:    mean = a.meanexcept AttributeError:    return _wrapit(a, 'mean', axis, dtype, out)re...</p></div><div class="post-footer"><div class="meta"><div class="info"><i class="fa fa-sun-o"></i><span class="date">2017-07-20</span><i class="fa fa-comment-o"></i><a href="/posts/numpy中mean跟average区别/#comments">评论</a><i class="fa fa-tag"></i><a class="tag" href="/tags/机器学习/" title="机器学习">机器学习 </a></div></div></div></div><div class="post animated fadeInDown"><div class="post-title"><h3><a href="/posts/pandas-index区别/">pandas中iloc loc ix的区别</a></h3></div><div class="post-content"><p>iloc[行号]loc[行标签]ix[两种都可]  
</p></div><div class="post-footer"><div class="meta"><div class="info"><i class="fa fa-sun-o"></i><span class="date">2017-07-20</span><i class="fa fa-comment-o"></i><a href="/posts/pandas-index区别/#comments">评论</a><i class="fa fa-tag"></i><a class="tag" href="/tags/机器学习/" title="机器学习">机器学习 </a></div></div></div></div><div class="post animated fadeInDown"><div class="post-title"><h3><a href="/posts/notebook无法直接打开浏览器/">notebook无法直接打开浏览器</a></h3></div><div class="post-content"><p>把 jupyter 配置文件 ~/.jupyter/jupyter_notebook_config.py中的123c.NotebookApp.browser = u&apos;Chrome&apos;c.NotebookApp.token = &apos;&apos;c.NotebookApp.password ...</p></div><div class="post-footer"><div class="meta"><div class="info"><i class="fa fa-sun-o"></i><span class="date">2017-07-20</span><i class="fa fa-comment-o"></i><a href="/posts/notebook无法直接打开浏览器/#comments">评论</a><i class="fa fa-tag"></i><a class="tag" href="/tags/机器学习/" title="机器学习">机器学习 </a></div></div></div></div><div class="pagination"><ul class="clearfix"><li class="pre pagbuttons"><a class="btn" role="navigation" href="/page/6/">上一页</a></li><li class="next pagbuttons"><a class="btn" role="navigation" href="/page/8/">下一页</a></li></ul></div></div></div></div><script src="/js/jquery.js"></script><script src="/js/jquery-migrate-1.2.1.min.js"></script><script src="/js/jquery.appear.js"></script></body></html>