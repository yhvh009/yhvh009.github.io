<!DOCTYPE html><html lang="zh-CN"><head><meta charset="utf-8"><meta name="X-UA-Compatible" content="IE=edge"><meta name="author" content="阳光夜风"><title>【课程笔记】回归 · 阳光夜风</title><!-- hexo-inject:begin --><!-- hexo-inject:end --><meta name="description" content="回归：连续数据分类：离散数据
本质：找到最佳拟合线
线性回归本质：找到y跟x之间的线性关系

y = mx + b

m是斜率（slope），b是截距（intercept）在sklearn中，斜率保存在 reg.coef_ 参数中，截距保存在 reg.intercept_ 参数中。

线性回归误差
"><meta name="keywords" content="Hexo,HTML,CSS,android,Linux"><meta content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=0" name="viewport"><meta content="yes" name="apple-mobile-web-app-capable"><meta content="black" name="apple-mobile-web-app-status-bar-style"><meta content="telephone=no" name="format-detection"><meta name="renderer" content="webkit"><link rel="short icon" href="/images/favicon.png" type="image/x-icon"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/blog_basic.css"><link rel="stylesheet" href="/css/font-awesome.min.css"><link rel="alternate" type="application/atom+xml" title="ATOM 1.0" href="/atom.xml"><!-- hexo-inject:begin --><!-- hexo-inject:end --></head><body><div class="sidebar animated fadeInDown"><div class="logo-title"><div class="title"><img src="/images/logo@2x.png" style="width:127px;"><h3 title=""><a href="/">阳光夜风</a></h3><div class="description"><p>上善若水 大盈若冲</p></div></div></div><ul class="social-links"><li><a href="http://weibo.com/1685261185"><i class="fa fa-weibo"></i></a></li></ul><div class="footer"></div></div><div class="main"><div class="page-top animated fadeInDown"><div class="nav"><li><a href="/">首页</a></li><li><a href="/about">关于</a></li><li><a href="/archives">归档</a></li><li><a href="/links">友链</a></li></div><div class="information"><div class="back_btn"><li><a class="fa fa-chevron-left" onclick="window.history.go(-1)"> </a></li></div><div class="avatar"><img src="/images/favicon.png"></div></div></div><div class="autopagerize_page_element"><div class="content"><div class="post-page"><div class="post animated fadeInDown"><div class="post-title"><h3><a>【课程笔记】回归</a></h3></div><div class="post-content"><p>回归：连续数据<br>分类：离散数据</p>
<!-- hexo-inject:begin --><!-- hexo-inject:end --><p>本质：找到最佳拟合线</p>
<h3 id="线性回归"><a href="#线性回归" class="headerlink" title="线性回归"></a>线性回归</h3><p>本质：找到y跟x之间的线性关系</p>
<blockquote>
<p>y = mx + b</p>
</blockquote>
<p>m是斜率（slope），b是截距（intercept）<br>在sklearn中，斜率保存在 <code>reg.coef_</code> 参数中，截距保存在 <code>reg.intercept_</code> 参数中。</p>
<p><img src="http://upload-images.jianshu.io/upload_images/276258-38f40a2cb6100815.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="image.png"></p>
<h5 id="线性回归误差"><a href="#线性回归误差" class="headerlink" title="线性回归误差"></a>线性回归误差</h5><ul>
<li><p>误差平方和（Sum of Squared Errors，SSE）</p>
<ul>
<li>Σ error<sub>i</sub><sup>2</sup></li>
<li><strong>如何最小化SSE</strong><ul>
<li>梯度下降法</li>
<li>普通最小二乘法（Ordinary Least Square，OLS），也是sklearn中使用的方法。</li>
</ul>
</li>
<li>缺点<ul>
<li>随样本数量增多而增加，即使表现很好或类似。如图：<br><img src="http://upload-images.jianshu.io/upload_images/276258-a2b658959ccec205.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="image.png"><br>两图表现类似，但由于SSE的特性是误差的总和，所以右图的SSE大于左图，所以不能很好的反应回归的拟合情况。</li>
</ul>
</li>
</ul>
</li>
<li><p>R<sup>2</sup></p>
<ul>
<li>表示随着X的变化，y的变化情况。</li>
<li>范围 0 - 1（0最差，1最好）</li>
</ul>
</li>
</ul>
</div><div class="post-footer"><div class="meta"><div class="info"><i class="fa fa-sun-o"></i><span class="date">2017-07-20</span><i class="fa fa-tag"></i><a class="tag" href="/tags/机器学习/" title="机器学习">机器学习 </a></div></div></div></div><div class="share"><div class="evernote"><a class="fa fa-bookmark" href="javascript:(function(){EN_CLIP_HOST='http://www.evernote.com';try{var%20x=document.createElement('SCRIPT');x.type='text/javascript';x.src=EN_CLIP_HOST+'/public/bookmarkClipper.js?'+(new%20Date().getTime()/100000);document.getElementsByTagName('head')[0].appendChild(x);}catch(e){location.href=EN_CLIP_HOST+'/clip.action?url='+encodeURIComponent(location.href)+'&amp;title='+encodeURIComponent(document.title);}})();" ref="nofollow" target="_blank"></a></div><div class="weibo"><a class="fa fa-weibo" href="javascript:void((function(s,d,e){try{}catch(e){}var f='http://service.weibo.com/share/share.php?',u=d.location.href,p=['url=',e(u),'&amp;title=',e(d.title),'&amp;appkey=2924220432'].join('');function a(){if(!window.open([f,p].join(''),'mb',['toolbar=0,status=0,resizable=1,width=620,height=450,left=',(s.width-620)/2,',top=',(s.height-450)/2].join('')))u.href=[f,p].join('');};if(/Firefox/.test(navigator.userAgent)){setTimeout(a,0)}else{a()}})(screen,document,encodeURIComponent));"></a></div><div class="twitter"><a class="fa fa-twitter" href="http://twitter.com/home?status=,http://yoursite.com/posts/【课程笔记】回归/,阳光夜风,【课程笔记】回归,;"></a></div></div><div class="pagination"><ul class="clearfix"><li class="pre pagbuttons"><a class="btn" role="navigation" href="/posts/【课程笔记】分类/" title="【课程笔记】分类">上一篇</a></li><li class="next pagbuttons"><a class="btn" role="navigation" href="/posts/np-std跟pd-std的区别/" title="np.std跟pd.std的区别">下一篇</a></li></ul></div></div></div></div></div><script src="/js/jquery.js"></script><script src="/js/jquery-migrate-1.2.1.min.js"></script><script src="/js/jquery.appear.js"></script><!-- hexo-inject:begin --><!-- hexo-inject:end --></body></html>